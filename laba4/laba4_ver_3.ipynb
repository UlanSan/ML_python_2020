{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "SEED = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные по шахматным турнирам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_id</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_id</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>moves</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TZJHLljE</td>\n",
       "      <td>False</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>15+2</td>\n",
       "      <td>bourgris</td>\n",
       "      <td>1500</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1191</td>\n",
       "      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n",
       "      <td>D10</td>\n",
       "      <td>Slav Defense: Exchange Variation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1NXvwaE</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+10</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1322</td>\n",
       "      <td>skinnerua</td>\n",
       "      <td>1261</td>\n",
       "      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n",
       "      <td>B00</td>\n",
       "      <td>Nimzowitsch Defense: Kennedy Variation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mIICvQHh</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>5+10</td>\n",
       "      <td>ischia</td>\n",
       "      <td>1496</td>\n",
       "      <td>a-00</td>\n",
       "      <td>1500</td>\n",
       "      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n",
       "      <td>C20</td>\n",
       "      <td>King's Pawn Game: Leonardis Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kWKvrqYL</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>20+0</td>\n",
       "      <td>daniamurashov</td>\n",
       "      <td>1439</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1454</td>\n",
       "      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n",
       "      <td>D02</td>\n",
       "      <td>Queen's Pawn Game: Zukertort Variation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9tXo1AUZ</td>\n",
       "      <td>True</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>30+3</td>\n",
       "      <td>nik221107</td>\n",
       "      <td>1523</td>\n",
       "      <td>adivanov2009</td>\n",
       "      <td>1469</td>\n",
       "      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n",
       "      <td>C41</td>\n",
       "      <td>Philidor Defense</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
       "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
       "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
       "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
       "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
       "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
       "\n",
       "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
       "0           15+2       bourgris          1500          a-00          1191   \n",
       "1           5+10           a-00          1322     skinnerua          1261   \n",
       "2           5+10         ischia          1496          a-00          1500   \n",
       "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
       "4           30+3      nik221107          1523  adivanov2009          1469   \n",
       "\n",
       "                                               moves opening_eco  \\\n",
       "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
       "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
       "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
       "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
       "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
       "\n",
       "                             opening_name  opening_ply  \n",
       "0        Slav Defense: Exchange Variation            5  \n",
       "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
       "2   King's Pawn Game: Leonardis Variation            3  \n",
       "3  Queen's Pawn Game: Zukertort Variation            3  \n",
       "4                        Philidor Defense            5  "
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'Data\\games.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.005800e+04</td>\n",
       "      <td>2.005800e+04</td>\n",
       "      <td>20058.000000</td>\n",
       "      <td>20058.000000</td>\n",
       "      <td>20058.000000</td>\n",
       "      <td>20058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.483617e+12</td>\n",
       "      <td>1.483618e+12</td>\n",
       "      <td>60.465999</td>\n",
       "      <td>1596.631868</td>\n",
       "      <td>1588.831987</td>\n",
       "      <td>4.816981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.850151e+10</td>\n",
       "      <td>2.850140e+10</td>\n",
       "      <td>33.570585</td>\n",
       "      <td>291.253376</td>\n",
       "      <td>291.036126</td>\n",
       "      <td>2.797152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.376772e+12</td>\n",
       "      <td>1.376772e+12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.477548e+12</td>\n",
       "      <td>1.477548e+12</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>1391.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.496010e+12</td>\n",
       "      <td>1.496010e+12</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1562.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.503170e+12</td>\n",
       "      <td>1.503170e+12</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1793.000000</td>\n",
       "      <td>1784.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.504493e+12</td>\n",
       "      <td>1.504494e+12</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2723.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_at  last_move_at         turns  white_rating  black_rating  \\\n",
       "count  2.005800e+04  2.005800e+04  20058.000000  20058.000000  20058.000000   \n",
       "mean   1.483617e+12  1.483618e+12     60.465999   1596.631868   1588.831987   \n",
       "std    2.850151e+10  2.850140e+10     33.570585    291.253376    291.036126   \n",
       "min    1.376772e+12  1.376772e+12      1.000000    784.000000    789.000000   \n",
       "25%    1.477548e+12  1.477548e+12     37.000000   1398.000000   1391.000000   \n",
       "50%    1.496010e+12  1.496010e+12     55.000000   1567.000000   1562.000000   \n",
       "75%    1.503170e+12  1.503170e+12     79.000000   1793.000000   1784.000000   \n",
       "max    1.504493e+12  1.504494e+12    349.000000   2700.000000   2723.000000   \n",
       "\n",
       "        opening_ply  \n",
       "count  20058.000000  \n",
       "mean       4.816981  \n",
       "std        2.797152  \n",
       "min        1.000000  \n",
       "25%        3.000000  \n",
       "50%        4.000000  \n",
       "75%        6.000000  \n",
       "max       28.000000  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20058, 16)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20058 entries, 0 to 20057\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              20058 non-null  object \n",
      " 1   rated           20058 non-null  bool   \n",
      " 2   created_at      20058 non-null  float64\n",
      " 3   last_move_at    20058 non-null  float64\n",
      " 4   turns           20058 non-null  int64  \n",
      " 5   victory_status  20058 non-null  object \n",
      " 6   winner          20058 non-null  object \n",
      " 7   increment_code  20058 non-null  object \n",
      " 8   white_id        20058 non-null  object \n",
      " 9   white_rating    20058 non-null  int64  \n",
      " 10  black_id        20058 non-null  object \n",
      " 11  black_rating    20058 non-null  int64  \n",
      " 12  moves           20058 non-null  object \n",
      " 13  opening_eco     20058 non-null  object \n",
      " 14  opening_name    20058 non-null  object \n",
      " 15  opening_ply     20058 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(4), object(9)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     16155\n",
       "False     3903\n",
       "Name: rated, dtype: int64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resign       11147\n",
       "mate          6325\n",
       "outoftime     1680\n",
       "draw           906\n",
       "Name: victory_status, dtype: int64"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['victory_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white    10001\n",
       "black     9107\n",
       "draw       950\n",
       "Name: winner, dtype: int64"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['winner'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['id','increment_code', 'white_id','black_id','moves','opening_eco','opening_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['rated'] = df['rated'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['victory_status'] = df2['victory_status'].replace({'resign':0,\n",
    "                                                       'mate':1,\n",
    "                                                       'outoftime':2,\n",
    "                                                       'draw':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['winner'] = df2['winner'].replace({'white':0,'black':1,'draw':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1191</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>1.504110e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>1454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>1.504030e+12</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1523</td>\n",
       "      <td>1469</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated    created_at  last_move_at  turns  victory_status  winner  \\\n",
       "0      0  1.504210e+12  1.504210e+12     13               2       0   \n",
       "1      1  1.504130e+12  1.504130e+12     16               0       1   \n",
       "2      1  1.504130e+12  1.504130e+12     61               1       0   \n",
       "3      1  1.504110e+12  1.504110e+12     61               1       0   \n",
       "4      1  1.504030e+12  1.504030e+12     95               1       0   \n",
       "\n",
       "   white_rating  black_rating  opening_ply  \n",
       "0          1500          1191            5  \n",
       "1          1322          1261            4  \n",
       "2          1496          1500            3  \n",
       "3          1439          1454            3  \n",
       "4          1523          1469            5  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20058 entries, 0 to 20057\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   rated           20058 non-null  int32  \n",
      " 1   created_at      20058 non-null  float64\n",
      " 2   last_move_at    20058 non-null  float64\n",
      " 3   turns           20058 non-null  int64  \n",
      " 4   victory_status  20058 non-null  int64  \n",
      " 5   winner          20058 non-null  int64  \n",
      " 6   white_rating    20058 non-null  int64  \n",
      " 7   black_rating    20058 non-null  int64  \n",
      " 8   opening_ply     20058 non-null  int64  \n",
      "dtypes: float64(2), int32(1), int64(6)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор Х и У"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['winner']\n",
    "x = df2.drop(['winner'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перобразование y в массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "Name: winner, dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rated</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_move_at</th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_ply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>1.504210e+12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>1191</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>1.504130e+12</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rated    created_at  last_move_at  turns  victory_status  white_rating  \\\n",
       "0      0  1.504210e+12  1.504210e+12     13               2          1500   \n",
       "1      1  1.504130e+12  1.504130e+12     16               0          1322   \n",
       "2      1  1.504130e+12  1.504130e+12     61               1          1496   \n",
       "\n",
       "   black_rating  opening_ply  \n",
       "0          1191            5  \n",
       "1          1261            4  \n",
       "2          1500            3  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование х в матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.50421000e+12, 1.50421000e+12, ...,\n",
       "        1.50000000e+03, 1.19100000e+03, 5.00000000e+00],\n",
       "       [1.00000000e+00, 1.50413000e+12, 1.50413000e+12, ...,\n",
       "        1.32200000e+03, 1.26100000e+03, 4.00000000e+00],\n",
       "       [1.00000000e+00, 1.50413000e+12, 1.50413000e+12, ...,\n",
       "        1.49600000e+03, 1.50000000e+03, 3.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.49969788e+12, 1.49969805e+12, ...,\n",
       "        1.21900000e+03, 1.28600000e+03, 3.00000000e+00],\n",
       "       [1.00000000e+00, 1.49969613e+12, 1.49969707e+12, ...,\n",
       "        1.36000000e+03, 1.22700000e+03, 4.00000000e+00],\n",
       "       [1.00000000e+00, 1.49964315e+12, 1.49964389e+12, ...,\n",
       "        1.23500000e+03, 1.33900000e+03, 3.00000000e+00]])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = train_y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.43613532e+12, 1.43613636e+12, ...,\n",
       "        1.68900000e+03, 1.57800000e+03, 2.00000000e+00],\n",
       "       [1.00000000e+00, 1.48575534e+12, 1.48575629e+12, ...,\n",
       "        1.64200000e+03, 1.48500000e+03, 4.00000000e+00],\n",
       "       [1.00000000e+00, 1.50114957e+12, 1.50115005e+12, ...,\n",
       "        1.70400000e+03, 1.82400000e+03, 2.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.49577000e+12, 1.49577000e+12, ...,\n",
       "        1.78500000e+03, 1.43200000e+03, 5.00000000e+00],\n",
       "       [1.00000000e+00, 1.47482000e+12, 1.47482000e+12, ...,\n",
       "        1.42200000e+03, 2.02600000e+03, 5.00000000e+00],\n",
       "       [0.00000000e+00, 1.46324000e+12, 1.46325000e+12, ...,\n",
       "        1.73100000e+03, 1.86600000e+03, 2.00000000e+00]])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.50353000e+12, 1.50353000e+12, ...,\n",
       "        1.48900000e+03, 1.59200000e+03, 3.00000000e+00],\n",
       "       [1.00000000e+00, 1.50400396e+12, 1.50400416e+12, ...,\n",
       "        1.39800000e+03, 1.43600000e+03, 5.00000000e+00],\n",
       "       [1.00000000e+00, 1.50308294e+12, 1.50308396e+12, ...,\n",
       "        2.16200000e+03, 2.12200000e+03, 7.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.50356690e+12, 1.50356727e+12, ...,\n",
       "        1.59200000e+03, 1.67100000e+03, 5.00000000e+00],\n",
       "       [0.00000000e+00, 1.49673336e+12, 1.49673421e+12, ...,\n",
       "        1.79900000e+03, 1.50000000e+03, 8.00000000e+00],\n",
       "       [1.00000000e+00, 1.50333000e+12, 1.50333000e+12, ...,\n",
       "        1.96900000e+03, 2.24700000e+03, 5.00000000e+00]])"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = pd.DataFrame(train_x).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLPClassifier(hidden_layer_sizes=(50,50,50,50), activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 50, 50, 50))"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_mlp = model_mlp.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2011,    0],\n",
       "       [   0, 1799,    0],\n",
       "       [   0,  202,    0]], dtype=int64)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_mlp = confusion_matrix(test_y, y_hat_mlp)\n",
    "cm_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ulaan saan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.44840479, 0.        ]),\n",
       " array([0., 1., 0.]),\n",
       " array([0.        , 0.61917054, 0.        ]),\n",
       " array([2011, 1799,  202], dtype=int64))"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y, y_hat_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4484047856430708"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_hat_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_mlp, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = keras.Sequential()\n",
    "model_keras.add(layers.Dense(150, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras.add(layers.Dense(100, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras.add(layers.Dense(50, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model_keras.compile(keras.optimizers.SGD(learning_rate=0.001), \n",
    "          keras.losses.MeanSquaredError(reduction='sum'),\n",
    "          metrics=['accuracy']\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y2 = []\n",
    "for y in train_y:\n",
    "    y2 = np.zeros(10)\n",
    "    y2[y] = 1\n",
    "    train_y2.append(y2)\n",
    "    \n",
    "test_y2 = []\n",
    "for y in test_y:\n",
    "    y2 = np.zeros(10)\n",
    "    y2[y] = 1\n",
    "    test_y2.append(y2)\n",
    "    \n",
    "train_y2 = np.array(train_y2)\n",
    "test_y2 = np.array(test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16046, 10)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16046, 8)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 2.0832 - accuracy: 0.4819\n",
      "Epoch 2/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9473 - accuracy: 0.4852\n",
      "Epoch 3/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9447 - accuracy: 0.4924\n",
      "Epoch 4/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9446 - accuracy: 0.4885\n",
      "Epoch 5/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9411 - accuracy: 0.4909\n",
      "Epoch 6/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9410 - accuracy: 0.4893\n",
      "Epoch 7/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9401 - accuracy: 0.4953\n",
      "Epoch 8/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9394 - accuracy: 0.4910\n",
      "Epoch 9/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9395 - accuracy: 0.4867\n",
      "Epoch 10/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9368 - accuracy: 0.4966\n",
      "Epoch 11/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9381 - accuracy: 0.4901\n",
      "Epoch 12/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9356 - accuracy: 0.4960\n",
      "Epoch 13/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9361 - accuracy: 0.4936\n",
      "Epoch 14/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9356 - accuracy: 0.4924\n",
      "Epoch 15/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9340 - accuracy: 0.4928\n",
      "Epoch 16/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9346 - accuracy: 0.4887\n",
      "Epoch 17/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9337 - accuracy: 0.4893\n",
      "Epoch 18/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9323 - accuracy: 0.4917\n",
      "Epoch 19/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9330 - accuracy: 0.4913\n",
      "Epoch 20/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9326 - accuracy: 0.4906\n",
      "Epoch 21/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9320 - accuracy: 0.4918\n",
      "Epoch 22/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9322 - accuracy: 0.4907\n",
      "Epoch 23/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9311 - accuracy: 0.4934\n",
      "Epoch 24/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9313 - accuracy: 0.4898\n",
      "Epoch 25/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9306 - accuracy: 0.4937\n",
      "Epoch 26/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9288 - accuracy: 0.4941\n",
      "Epoch 27/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9299 - accuracy: 0.4926\n",
      "Epoch 28/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9286 - accuracy: 0.4921\n",
      "Epoch 29/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9284 - accuracy: 0.4946\n",
      "Epoch 30/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9277 - accuracy: 0.4946\n",
      "Epoch 31/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9280 - accuracy: 0.4900\n",
      "Epoch 32/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9275 - accuracy: 0.4917\n",
      "Epoch 33/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9267 - accuracy: 0.4899\n",
      "Epoch 34/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9258 - accuracy: 0.4925\n",
      "Epoch 35/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9256 - accuracy: 0.4921\n",
      "Epoch 36/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9243 - accuracy: 0.4927\n",
      "Epoch 37/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9255 - accuracy: 0.4918\n",
      "Epoch 38/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9239 - accuracy: 0.4930\n",
      "Epoch 39/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9236 - accuracy: 0.4914\n",
      "Epoch 40/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9233 - accuracy: 0.4908\n",
      "Epoch 41/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9230 - accuracy: 0.4947\n",
      "Epoch 42/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9230 - accuracy: 0.4922\n",
      "Epoch 43/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9229 - accuracy: 0.4918\n",
      "Epoch 44/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9228 - accuracy: 0.4911\n",
      "Epoch 45/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9217 - accuracy: 0.4948\n",
      "Epoch 46/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9213 - accuracy: 0.4953\n",
      "Epoch 47/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9219 - accuracy: 0.4922\n",
      "Epoch 48/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9203 - accuracy: 0.4905\n",
      "Epoch 49/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9217 - accuracy: 0.4931\n",
      "Epoch 50/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9187 - accuracy: 0.4927\n",
      "Epoch 51/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9189 - accuracy: 0.4933\n",
      "Epoch 52/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9194 - accuracy: 0.4931\n",
      "Epoch 53/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9186 - accuracy: 0.4952\n",
      "Epoch 54/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9176 - accuracy: 0.4973\n",
      "Epoch 55/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9178 - accuracy: 0.4943\n",
      "Epoch 56/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9177 - accuracy: 0.4956\n",
      "Epoch 57/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9169 - accuracy: 0.4930\n",
      "Epoch 58/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9172 - accuracy: 0.4923\n",
      "Epoch 59/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9158 - accuracy: 0.4930\n",
      "Epoch 60/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9163 - accuracy: 0.4940\n",
      "Epoch 61/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9168 - accuracy: 0.4947\n",
      "Epoch 62/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9156 - accuracy: 0.4946\n",
      "Epoch 63/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9154 - accuracy: 0.4940\n",
      "Epoch 64/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9144 - accuracy: 0.4941\n",
      "Epoch 65/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9145 - accuracy: 0.4915\n",
      "Epoch 66/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9144 - accuracy: 0.4951\n",
      "Epoch 67/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9134 - accuracy: 0.4955\n",
      "Epoch 68/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9137 - accuracy: 0.4933\n",
      "Epoch 69/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9128 - accuracy: 0.4941\n",
      "Epoch 70/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9129 - accuracy: 0.4936\n",
      "Epoch 71/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9113 - accuracy: 0.4929\n",
      "Epoch 72/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9114 - accuracy: 0.4908\n",
      "Epoch 73/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9113 - accuracy: 0.4918\n",
      "Epoch 74/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9109 - accuracy: 0.4930\n",
      "Epoch 75/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9112 - accuracy: 0.4958\n",
      "Epoch 76/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9105 - accuracy: 0.4933\n",
      "Epoch 77/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9100 - accuracy: 0.4936\n",
      "Epoch 78/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9086 - accuracy: 0.4928\n",
      "Epoch 79/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9087 - accuracy: 0.4953\n",
      "Epoch 80/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9092 - accuracy: 0.4935\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9086 - accuracy: 0.4952\n",
      "Epoch 82/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9083 - accuracy: 0.4941\n",
      "Epoch 83/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9082 - accuracy: 0.4921\n",
      "Epoch 84/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9068 - accuracy: 0.4917\n",
      "Epoch 85/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9069 - accuracy: 0.4924\n",
      "Epoch 86/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9075 - accuracy: 0.4940\n",
      "Epoch 87/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9068 - accuracy: 0.4933\n",
      "Epoch 88/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9061 - accuracy: 0.4925\n",
      "Epoch 89/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9062 - accuracy: 0.4935\n",
      "Epoch 90/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9060 - accuracy: 0.4945\n",
      "Epoch 91/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9051 - accuracy: 0.4947\n",
      "Epoch 92/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9048 - accuracy: 0.4918\n",
      "Epoch 93/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9038 - accuracy: 0.4930\n",
      "Epoch 94/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9042 - accuracy: 0.4922\n",
      "Epoch 95/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9035 - accuracy: 0.4942\n",
      "Epoch 96/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9039 - accuracy: 0.4955\n",
      "Epoch 97/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9030 - accuracy: 0.4943\n",
      "Epoch 98/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9022 - accuracy: 0.4924\n",
      "Epoch 99/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9035 - accuracy: 0.4931\n",
      "Epoch 100/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9024 - accuracy: 0.4976\n",
      "Epoch 101/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9006 - accuracy: 0.4943\n",
      "Epoch 102/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9014 - accuracy: 0.4930\n",
      "Epoch 103/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9008 - accuracy: 0.4947\n",
      "Epoch 104/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9007 - accuracy: 0.4950\n",
      "Epoch 105/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9006 - accuracy: 0.4927\n",
      "Epoch 106/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9004 - accuracy: 0.4942\n",
      "Epoch 107/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8996 - accuracy: 0.4925\n",
      "Epoch 108/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8998 - accuracy: 0.4952\n",
      "Epoch 109/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8992 - accuracy: 0.4928\n",
      "Epoch 110/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8991 - accuracy: 0.4918\n",
      "Epoch 111/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8986 - accuracy: 0.4948\n",
      "Epoch 112/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8976 - accuracy: 0.4917\n",
      "Epoch 113/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8978 - accuracy: 0.4911\n",
      "Epoch 114/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8976 - accuracy: 0.4923\n",
      "Epoch 115/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8972 - accuracy: 0.4953\n",
      "Epoch 116/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8967 - accuracy: 0.4933\n",
      "Epoch 117/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8964 - accuracy: 0.4928\n",
      "Epoch 118/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8968 - accuracy: 0.4969\n",
      "Epoch 119/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8957 - accuracy: 0.4903\n",
      "Epoch 120/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8959 - accuracy: 0.4925\n",
      "Epoch 121/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8955 - accuracy: 0.4959\n",
      "Epoch 122/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8950 - accuracy: 0.4929\n",
      "Epoch 123/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8947 - accuracy: 0.4931\n",
      "Epoch 124/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8942 - accuracy: 0.4950\n",
      "Epoch 125/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8949 - accuracy: 0.4952\n",
      "Epoch 126/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8940 - accuracy: 0.4922\n",
      "Epoch 127/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8934 - accuracy: 0.4900\n",
      "Epoch 128/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8929 - accuracy: 0.4925\n",
      "Epoch 129/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8926 - accuracy: 0.4945\n",
      "Epoch 130/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8921 - accuracy: 0.4937\n",
      "Epoch 131/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8921 - accuracy: 0.4944\n",
      "Epoch 132/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8913 - accuracy: 0.4932\n",
      "Epoch 133/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8916 - accuracy: 0.4913\n",
      "Epoch 134/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8913 - accuracy: 0.4934\n",
      "Epoch 135/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8908 - accuracy: 0.4921\n",
      "Epoch 136/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8910 - accuracy: 0.4948\n",
      "Epoch 137/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8900 - accuracy: 0.4918\n",
      "Epoch 138/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8893 - accuracy: 0.4959\n",
      "Epoch 139/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8891 - accuracy: 0.4943\n",
      "Epoch 140/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8899 - accuracy: 0.4936\n",
      "Epoch 141/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8895 - accuracy: 0.4963\n",
      "Epoch 142/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8869 - accuracy: 0.4981\n",
      "Epoch 143/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8888 - accuracy: 0.4942\n",
      "Epoch 144/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8880 - accuracy: 0.4945\n",
      "Epoch 145/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8877 - accuracy: 0.4958\n",
      "Epoch 146/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8872 - accuracy: 0.4956\n",
      "Epoch 147/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8877 - accuracy: 0.4937\n",
      "Epoch 148/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8867 - accuracy: 0.4968\n",
      "Epoch 149/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8866 - accuracy: 0.4917\n",
      "Epoch 150/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8855 - accuracy: 0.4951\n",
      "Epoch 151/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8859 - accuracy: 0.4948\n",
      "Epoch 152/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8850 - accuracy: 0.4925\n",
      "Epoch 153/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8855 - accuracy: 0.4952\n",
      "Epoch 154/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8848 - accuracy: 0.4956\n",
      "Epoch 155/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8848 - accuracy: 0.4925\n",
      "Epoch 156/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8849 - accuracy: 0.4955\n",
      "Epoch 157/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8842 - accuracy: 0.4928\n",
      "Epoch 158/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8842 - accuracy: 0.4925\n",
      "Epoch 159/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8825 - accuracy: 0.4946\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8834 - accuracy: 0.4925\n",
      "Epoch 161/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8832 - accuracy: 0.4948\n",
      "Epoch 162/500\n",
      "502/502 [==============================] - ETA: 0s - loss: 1.8835 - accuracy: 0.49 - 1s 1ms/step - loss: 1.8821 - accuracy: 0.4922\n",
      "Epoch 163/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8831 - accuracy: 0.4913\n",
      "Epoch 164/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8822 - accuracy: 0.4941\n",
      "Epoch 165/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8820 - accuracy: 0.4936\n",
      "Epoch 166/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8816 - accuracy: 0.4961\n",
      "Epoch 167/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8809 - accuracy: 0.4897\n",
      "Epoch 168/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8803 - accuracy: 0.4910\n",
      "Epoch 169/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8804 - accuracy: 0.4955\n",
      "Epoch 170/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8805 - accuracy: 0.4950\n",
      "Epoch 171/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8805 - accuracy: 0.4967\n",
      "Epoch 172/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8797 - accuracy: 0.4934\n",
      "Epoch 173/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8793 - accuracy: 0.4966\n",
      "Epoch 174/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8793 - accuracy: 0.4956\n",
      "Epoch 175/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8789 - accuracy: 0.4930\n",
      "Epoch 176/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8793 - accuracy: 0.4955: 0s - loss: 1.884\n",
      "Epoch 177/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8781 - accuracy: 0.4957\n",
      "Epoch 178/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8778 - accuracy: 0.4966\n",
      "Epoch 179/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8779 - accuracy: 0.4953\n",
      "Epoch 180/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8773 - accuracy: 0.4965\n",
      "Epoch 181/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8768 - accuracy: 0.4933\n",
      "Epoch 182/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8772 - accuracy: 0.4945\n",
      "Epoch 183/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8772 - accuracy: 0.4955\n",
      "Epoch 184/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8764 - accuracy: 0.4930\n",
      "Epoch 185/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8754 - accuracy: 0.4930\n",
      "Epoch 186/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8756 - accuracy: 0.4921: 0s - loss: 1.8\n",
      "Epoch 187/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8759 - accuracy: 0.4939\n",
      "Epoch 188/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8755 - accuracy: 0.4950\n",
      "Epoch 189/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8754 - accuracy: 0.4928\n",
      "Epoch 190/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8748 - accuracy: 0.4933\n",
      "Epoch 191/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8750 - accuracy: 0.4909\n",
      "Epoch 192/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8743 - accuracy: 0.4928\n",
      "Epoch 193/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8736 - accuracy: 0.4916\n",
      "Epoch 194/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8732 - accuracy: 0.4981\n",
      "Epoch 195/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8732 - accuracy: 0.4925\n",
      "Epoch 196/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8732 - accuracy: 0.4933\n",
      "Epoch 197/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8726 - accuracy: 0.4945\n",
      "Epoch 198/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8716 - accuracy: 0.4941\n",
      "Epoch 199/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8725 - accuracy: 0.4939\n",
      "Epoch 200/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8719 - accuracy: 0.4936\n",
      "Epoch 201/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8720 - accuracy: 0.4938\n",
      "Epoch 202/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8715 - accuracy: 0.4940\n",
      "Epoch 203/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8711 - accuracy: 0.4921\n",
      "Epoch 204/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8713 - accuracy: 0.4940\n",
      "Epoch 205/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8708 - accuracy: 0.4959\n",
      "Epoch 206/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8702 - accuracy: 0.4940\n",
      "Epoch 207/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8701 - accuracy: 0.4967\n",
      "Epoch 208/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8696 - accuracy: 0.4950\n",
      "Epoch 209/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8699 - accuracy: 0.4948\n",
      "Epoch 210/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8694 - accuracy: 0.4957\n",
      "Epoch 211/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8690 - accuracy: 0.4939\n",
      "Epoch 212/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8690 - accuracy: 0.4955\n",
      "Epoch 213/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8682 - accuracy: 0.4942\n",
      "Epoch 214/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8678 - accuracy: 0.4960\n",
      "Epoch 215/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8683 - accuracy: 0.4931\n",
      "Epoch 216/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8673 - accuracy: 0.4953\n",
      "Epoch 217/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8675 - accuracy: 0.4945\n",
      "Epoch 218/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8668 - accuracy: 0.4923\n",
      "Epoch 219/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8665 - accuracy: 0.4931\n",
      "Epoch 220/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8667 - accuracy: 0.4948\n",
      "Epoch 221/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8668 - accuracy: 0.4948\n",
      "Epoch 222/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8656 - accuracy: 0.4953\n",
      "Epoch 223/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8647 - accuracy: 0.4975\n",
      "Epoch 224/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8659 - accuracy: 0.4938\n",
      "Epoch 225/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8651 - accuracy: 0.4921\n",
      "Epoch 226/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8651 - accuracy: 0.4942\n",
      "Epoch 227/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8648 - accuracy: 0.4960\n",
      "Epoch 228/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8648 - accuracy: 0.4941\n",
      "Epoch 229/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8640 - accuracy: 0.4943\n",
      "Epoch 230/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8647 - accuracy: 0.4952\n",
      "Epoch 231/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8642 - accuracy: 0.4943\n",
      "Epoch 232/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8631 - accuracy: 0.4953\n",
      "Epoch 233/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8633 - accuracy: 0.4943\n",
      "Epoch 234/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8623 - accuracy: 0.4973\n",
      "Epoch 235/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8634 - accuracy: 0.4938\n",
      "Epoch 236/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8631 - accuracy: 0.4951\n",
      "Epoch 237/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8617 - accuracy: 0.4937\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8623 - accuracy: 0.4944\n",
      "Epoch 239/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8621 - accuracy: 0.4963\n",
      "Epoch 240/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8606 - accuracy: 0.4930\n",
      "Epoch 241/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8614 - accuracy: 0.4948\n",
      "Epoch 242/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8607 - accuracy: 0.4952\n",
      "Epoch 243/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8609 - accuracy: 0.4963\n",
      "Epoch 244/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8605 - accuracy: 0.4928\n",
      "Epoch 245/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8598 - accuracy: 0.4913\n",
      "Epoch 246/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8598 - accuracy: 0.4900\n",
      "Epoch 247/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8591 - accuracy: 0.4955\n",
      "Epoch 248/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8589 - accuracy: 0.4935\n",
      "Epoch 249/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8586 - accuracy: 0.4951\n",
      "Epoch 250/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8593 - accuracy: 0.4928\n",
      "Epoch 251/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8591 - accuracy: 0.4953\n",
      "Epoch 252/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8582 - accuracy: 0.4932\n",
      "Epoch 253/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8585 - accuracy: 0.4933\n",
      "Epoch 254/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8580 - accuracy: 0.4936\n",
      "Epoch 255/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8573 - accuracy: 0.4966\n",
      "Epoch 256/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8571 - accuracy: 0.4944\n",
      "Epoch 257/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8573 - accuracy: 0.4940\n",
      "Epoch 258/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8573 - accuracy: 0.4941\n",
      "Epoch 259/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8570 - accuracy: 0.4940\n",
      "Epoch 260/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8566 - accuracy: 0.4938\n",
      "Epoch 261/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8561 - accuracy: 0.4923: 0s - loss: 1\n",
      "Epoch 262/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8559 - accuracy: 0.4944\n",
      "Epoch 263/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8558 - accuracy: 0.4932\n",
      "Epoch 264/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8555 - accuracy: 0.4953\n",
      "Epoch 265/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8553 - accuracy: 0.4940\n",
      "Epoch 266/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8551 - accuracy: 0.4928\n",
      "Epoch 267/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8550 - accuracy: 0.4961\n",
      "Epoch 268/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8548 - accuracy: 0.4956\n",
      "Epoch 269/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8543 - accuracy: 0.4938\n",
      "Epoch 270/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8547 - accuracy: 0.4962\n",
      "Epoch 271/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8541 - accuracy: 0.4959\n",
      "Epoch 272/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8541 - accuracy: 0.4949\n",
      "Epoch 273/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8538 - accuracy: 0.4950\n",
      "Epoch 274/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8530 - accuracy: 0.4930\n",
      "Epoch 275/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8520 - accuracy: 0.4980\n",
      "Epoch 276/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8523 - accuracy: 0.4919\n",
      "Epoch 277/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8527 - accuracy: 0.4949\n",
      "Epoch 278/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8519 - accuracy: 0.4972\n",
      "Epoch 279/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8514 - accuracy: 0.4943\n",
      "Epoch 280/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8515 - accuracy: 0.4923\n",
      "Epoch 281/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8519 - accuracy: 0.4950\n",
      "Epoch 282/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8519 - accuracy: 0.4950\n",
      "Epoch 283/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8517 - accuracy: 0.4946\n",
      "Epoch 284/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8510 - accuracy: 0.4962\n",
      "Epoch 285/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8504 - accuracy: 0.4940\n",
      "Epoch 286/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8509 - accuracy: 0.4961\n",
      "Epoch 287/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8500 - accuracy: 0.4949\n",
      "Epoch 288/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8499 - accuracy: 0.4933\n",
      "Epoch 289/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8503 - accuracy: 0.4942\n",
      "Epoch 290/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8502 - accuracy: 0.4940\n",
      "Epoch 291/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8490 - accuracy: 0.4952\n",
      "Epoch 292/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8490 - accuracy: 0.4965\n",
      "Epoch 293/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8482 - accuracy: 0.4959\n",
      "Epoch 294/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8489 - accuracy: 0.4970\n",
      "Epoch 295/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8488 - accuracy: 0.4944\n",
      "Epoch 296/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8482 - accuracy: 0.4961\n",
      "Epoch 297/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8479 - accuracy: 0.4938\n",
      "Epoch 298/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8462 - accuracy: 0.4949\n",
      "Epoch 299/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8473 - accuracy: 0.4948\n",
      "Epoch 300/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8472 - accuracy: 0.4945\n",
      "Epoch 301/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8471 - accuracy: 0.4961\n",
      "Epoch 302/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8469 - accuracy: 0.4952\n",
      "Epoch 303/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8468 - accuracy: 0.4950\n",
      "Epoch 304/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8464 - accuracy: 0.4959\n",
      "Epoch 305/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8460 - accuracy: 0.4943\n",
      "Epoch 306/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8456 - accuracy: 0.4945\n",
      "Epoch 307/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8459 - accuracy: 0.4953\n",
      "Epoch 308/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8461 - accuracy: 0.4963\n",
      "Epoch 309/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8452 - accuracy: 0.4910\n",
      "Epoch 310/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8453 - accuracy: 0.4955\n",
      "Epoch 311/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8449 - accuracy: 0.4955\n",
      "Epoch 312/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8444 - accuracy: 0.4944\n",
      "Epoch 313/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8447 - accuracy: 0.4946\n",
      "Epoch 314/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8440 - accuracy: 0.4981\n",
      "Epoch 315/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8443 - accuracy: 0.4966\n",
      "Epoch 316/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8429 - accuracy: 0.4988\n",
      "Epoch 317/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8434 - accuracy: 0.4913\n",
      "Epoch 318/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8421 - accuracy: 0.4956\n",
      "Epoch 319/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8428 - accuracy: 0.4945\n",
      "Epoch 320/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8431 - accuracy: 0.4930\n",
      "Epoch 321/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8427 - accuracy: 0.4942\n",
      "Epoch 322/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8424 - accuracy: 0.4923\n",
      "Epoch 323/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8424 - accuracy: 0.4973\n",
      "Epoch 324/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8420 - accuracy: 0.4930\n",
      "Epoch 325/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8417 - accuracy: 0.4973\n",
      "Epoch 326/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8417 - accuracy: 0.4962\n",
      "Epoch 327/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8409 - accuracy: 0.4952\n",
      "Epoch 328/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8411 - accuracy: 0.4970\n",
      "Epoch 329/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8408 - accuracy: 0.4953\n",
      "Epoch 330/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8414 - accuracy: 0.4941\n",
      "Epoch 331/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8409 - accuracy: 0.4943\n",
      "Epoch 332/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8401 - accuracy: 0.4943\n",
      "Epoch 333/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8406 - accuracy: 0.4963\n",
      "Epoch 334/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8399 - accuracy: 0.4948\n",
      "Epoch 335/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8396 - accuracy: 0.4962\n",
      "Epoch 336/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8396 - accuracy: 0.4955\n",
      "Epoch 337/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8393 - accuracy: 0.4968\n",
      "Epoch 338/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8391 - accuracy: 0.4962\n",
      "Epoch 339/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8391 - accuracy: 0.4945\n",
      "Epoch 340/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8388 - accuracy: 0.4926\n",
      "Epoch 341/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8384 - accuracy: 0.4958\n",
      "Epoch 342/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8383 - accuracy: 0.4941\n",
      "Epoch 343/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8383 - accuracy: 0.4950\n",
      "Epoch 344/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8381 - accuracy: 0.4953\n",
      "Epoch 345/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8380 - accuracy: 0.4926\n",
      "Epoch 346/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8375 - accuracy: 0.4975\n",
      "Epoch 347/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8377 - accuracy: 0.4933\n",
      "Epoch 348/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8364 - accuracy: 0.4959\n",
      "Epoch 349/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8374 - accuracy: 0.4922\n",
      "Epoch 350/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8362 - accuracy: 0.4943\n",
      "Epoch 351/500\n",
      "502/502 [==============================] - ETA: 0s - loss: 1.8380 - accuracy: 0.49 - 1s 1ms/step - loss: 1.8364 - accuracy: 0.4972\n",
      "Epoch 352/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8363 - accuracy: 0.4928\n",
      "Epoch 353/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8363 - accuracy: 0.4930\n",
      "Epoch 354/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8360 - accuracy: 0.4951\n",
      "Epoch 355/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8358 - accuracy: 0.4971\n",
      "Epoch 356/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8358 - accuracy: 0.4951\n",
      "Epoch 357/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8356 - accuracy: 0.4951\n",
      "Epoch 358/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8352 - accuracy: 0.4951\n",
      "Epoch 359/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8355 - accuracy: 0.4930\n",
      "Epoch 360/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8347 - accuracy: 0.4943\n",
      "Epoch 361/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8350 - accuracy: 0.4963\n",
      "Epoch 362/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8342 - accuracy: 0.4953\n",
      "Epoch 363/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8346 - accuracy: 0.4957\n",
      "Epoch 364/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8340 - accuracy: 0.4911\n",
      "Epoch 365/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8340 - accuracy: 0.4920\n",
      "Epoch 366/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8335 - accuracy: 0.4964\n",
      "Epoch 367/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8332 - accuracy: 0.4951\n",
      "Epoch 368/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8332 - accuracy: 0.4944\n",
      "Epoch 369/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8334 - accuracy: 0.4953\n",
      "Epoch 370/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8328 - accuracy: 0.4952\n",
      "Epoch 371/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8317 - accuracy: 0.4960\n",
      "Epoch 372/500\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.8322 - accuracy: 0.4946\n",
      "Epoch 373/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8320 - accuracy: 0.4953\n",
      "Epoch 374/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8321 - accuracy: 0.4964\n",
      "Epoch 375/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8319 - accuracy: 0.4948\n",
      "Epoch 376/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8317 - accuracy: 0.4971\n",
      "Epoch 377/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8311 - accuracy: 0.4943\n",
      "Epoch 378/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8308 - accuracy: 0.4914\n",
      "Epoch 379/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8306 - accuracy: 0.4956\n",
      "Epoch 380/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8312 - accuracy: 0.4951\n",
      "Epoch 381/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8307 - accuracy: 0.4953\n",
      "Epoch 382/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8305 - accuracy: 0.4940\n",
      "Epoch 383/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8300 - accuracy: 0.4948\n",
      "Epoch 384/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8298 - accuracy: 0.4945\n",
      "Epoch 385/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8300 - accuracy: 0.4957\n",
      "Epoch 386/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8298 - accuracy: 0.4942\n",
      "Epoch 387/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8297 - accuracy: 0.4958\n",
      "Epoch 388/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8300 - accuracy: 0.4946\n",
      "Epoch 389/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8292 - accuracy: 0.4956\n",
      "Epoch 390/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8290 - accuracy: 0.4940\n",
      "Epoch 391/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8292 - accuracy: 0.4963\n",
      "Epoch 392/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8284 - accuracy: 0.4934\n",
      "Epoch 393/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8285 - accuracy: 0.4956\n",
      "Epoch 394/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8279 - accuracy: 0.4937\n",
      "Epoch 395/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8280 - accuracy: 0.4951\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8283 - accuracy: 0.4941\n",
      "Epoch 397/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8275 - accuracy: 0.4945\n",
      "Epoch 398/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8281 - accuracy: 0.4956\n",
      "Epoch 399/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8274 - accuracy: 0.4961\n",
      "Epoch 400/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8276 - accuracy: 0.4966\n",
      "Epoch 401/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8269 - accuracy: 0.4959\n",
      "Epoch 402/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8271 - accuracy: 0.4963\n",
      "Epoch 403/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8268 - accuracy: 0.4952\n",
      "Epoch 404/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8266 - accuracy: 0.4963\n",
      "Epoch 405/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8266 - accuracy: 0.4948\n",
      "Epoch 406/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8259 - accuracy: 0.4908\n",
      "Epoch 407/500\n",
      "502/502 [==============================] - ETA: 0s - loss: 1.8265 - accuracy: 0.49 - 1s 1ms/step - loss: 1.8263 - accuracy: 0.4951\n",
      "Epoch 408/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8260 - accuracy: 0.4953\n",
      "Epoch 409/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8256 - accuracy: 0.4936\n",
      "Epoch 410/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8259 - accuracy: 0.4955\n",
      "Epoch 411/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8258 - accuracy: 0.4972\n",
      "Epoch 412/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8244 - accuracy: 0.4982\n",
      "Epoch 413/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8250 - accuracy: 0.4969\n",
      "Epoch 414/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8247 - accuracy: 0.4956\n",
      "Epoch 415/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8243 - accuracy: 0.4950\n",
      "Epoch 416/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8243 - accuracy: 0.4923\n",
      "Epoch 417/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8243 - accuracy: 0.4941\n",
      "Epoch 418/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8245 - accuracy: 0.4951\n",
      "Epoch 419/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8234 - accuracy: 0.4959\n",
      "Epoch 420/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8235 - accuracy: 0.4928\n",
      "Epoch 421/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8237 - accuracy: 0.4958\n",
      "Epoch 422/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8231 - accuracy: 0.4945\n",
      "Epoch 423/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8233 - accuracy: 0.4960\n",
      "Epoch 424/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8236 - accuracy: 0.4959\n",
      "Epoch 425/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8222 - accuracy: 0.4940\n",
      "Epoch 426/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8228 - accuracy: 0.4921\n",
      "Epoch 427/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8224 - accuracy: 0.4928\n",
      "Epoch 428/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8225 - accuracy: 0.4935\n",
      "Epoch 429/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8222 - accuracy: 0.4951\n",
      "Epoch 430/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8221 - accuracy: 0.4932\n",
      "Epoch 431/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8213 - accuracy: 0.4944\n",
      "Epoch 432/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8215 - accuracy: 0.4937\n",
      "Epoch 433/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8219 - accuracy: 0.4938\n",
      "Epoch 434/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8209 - accuracy: 0.4953\n",
      "Epoch 435/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8208 - accuracy: 0.4953\n",
      "Epoch 436/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8201 - accuracy: 0.4966\n",
      "Epoch 437/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8206 - accuracy: 0.4968\n",
      "Epoch 438/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8201 - accuracy: 0.4952\n",
      "Epoch 439/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8205 - accuracy: 0.4961\n",
      "Epoch 440/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8198 - accuracy: 0.4974\n",
      "Epoch 441/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8196 - accuracy: 0.4985\n",
      "Epoch 442/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8197 - accuracy: 0.4935\n",
      "Epoch 443/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8195 - accuracy: 0.4956\n",
      "Epoch 444/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8193 - accuracy: 0.4965\n",
      "Epoch 445/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8199 - accuracy: 0.4968\n",
      "Epoch 446/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8193 - accuracy: 0.4969\n",
      "Epoch 447/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8190 - accuracy: 0.4970\n",
      "Epoch 448/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8191 - accuracy: 0.4961\n",
      "Epoch 449/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8189 - accuracy: 0.4961\n",
      "Epoch 450/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8184 - accuracy: 0.4947\n",
      "Epoch 451/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8187 - accuracy: 0.4946\n",
      "Epoch 452/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8180 - accuracy: 0.4970\n",
      "Epoch 453/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8183 - accuracy: 0.4945\n",
      "Epoch 454/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8181 - accuracy: 0.4935\n",
      "Epoch 455/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8175 - accuracy: 0.4981\n",
      "Epoch 456/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8177 - accuracy: 0.4948\n",
      "Epoch 457/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8176 - accuracy: 0.4975\n",
      "Epoch 458/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8168 - accuracy: 0.4934\n",
      "Epoch 459/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8174 - accuracy: 0.4959\n",
      "Epoch 460/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8165 - accuracy: 0.4940\n",
      "Epoch 461/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8174 - accuracy: 0.4951\n",
      "Epoch 462/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8167 - accuracy: 0.4951\n",
      "Epoch 463/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8163 - accuracy: 0.4951\n",
      "Epoch 464/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8162 - accuracy: 0.4940\n",
      "Epoch 465/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8152 - accuracy: 0.4955\n",
      "Epoch 466/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8161 - accuracy: 0.4940\n",
      "Epoch 467/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8158 - accuracy: 0.4968\n",
      "Epoch 468/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8159 - accuracy: 0.4980\n",
      "Epoch 469/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8153 - accuracy: 0.4940\n",
      "Epoch 470/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8154 - accuracy: 0.4934\n",
      "Epoch 471/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8157 - accuracy: 0.4958\n",
      "Epoch 472/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8151 - accuracy: 0.4953\n",
      "Epoch 473/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8144 - accuracy: 0.4950\n",
      "Epoch 474/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8148 - accuracy: 0.4898\n",
      "Epoch 475/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8143 - accuracy: 0.4981\n",
      "Epoch 476/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8142 - accuracy: 0.4958\n",
      "Epoch 477/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8142 - accuracy: 0.4954\n",
      "Epoch 478/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8143 - accuracy: 0.4941\n",
      "Epoch 479/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8142 - accuracy: 0.4963\n",
      "Epoch 480/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8136 - accuracy: 0.4948\n",
      "Epoch 481/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8133 - accuracy: 0.4963\n",
      "Epoch 482/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8129 - accuracy: 0.4956\n",
      "Epoch 483/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8134 - accuracy: 0.4943\n",
      "Epoch 484/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8127 - accuracy: 0.4963\n",
      "Epoch 485/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8126 - accuracy: 0.4943\n",
      "Epoch 486/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8125 - accuracy: 0.4955\n",
      "Epoch 487/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8128 - accuracy: 0.4951\n",
      "Epoch 488/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8127 - accuracy: 0.4958\n",
      "Epoch 489/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8130 - accuracy: 0.4973\n",
      "Epoch 490/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8124 - accuracy: 0.4980\n",
      "Epoch 491/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8123 - accuracy: 0.4943\n",
      "Epoch 492/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8111 - accuracy: 0.4929\n",
      "Epoch 493/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8120 - accuracy: 0.4946\n",
      "Epoch 494/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8113 - accuracy: 0.4946\n",
      "Epoch 495/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8116 - accuracy: 0.4936\n",
      "Epoch 496/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8115 - accuracy: 0.4962\n",
      "Epoch 497/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8112 - accuracy: 0.4945\n",
      "Epoch 498/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8113 - accuracy: 0.4959\n",
      "Epoch 499/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8110 - accuracy: 0.4948\n",
      "Epoch 500/500\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.8107 - accuracy: 0.4955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c67143da60>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.fit(train_x, train_y2, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_keras = model_keras.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4785544 , 0.46801156, 0.04345587, ..., 0.000938  , 0.00179922,\n",
       "        0.00217526],\n",
       "       [0.4785544 , 0.46801156, 0.04345587, ..., 0.000938  , 0.00179922,\n",
       "        0.00217526],\n",
       "       [0.4785544 , 0.46801156, 0.04345587, ..., 0.000938  , 0.00179922,\n",
       "        0.00217526],\n",
       "       ...,\n",
       "       [0.4785544 , 0.46801156, 0.04345587, ..., 0.000938  , 0.00179922,\n",
       "        0.00217526],\n",
       "       [0.4785544 , 0.46801156, 0.04345587, ..., 0.000938  , 0.00179922,\n",
       "        0.00217526],\n",
       "       [0.4785544 , 0.46801156, 0.04345587, ..., 0.000938  , 0.00179922,\n",
       "        0.00217526]], dtype=float32)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_keras = [np.argmax(y) for y in y_hat_keras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2011,    0,    0],\n",
       "       [1799,    0,    0],\n",
       "       [ 202,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_keras = confusion_matrix(test_y, y_hat_keras)\n",
    "cm_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50124626, 0.        , 0.        ]),\n",
       " array([1., 0., 0.]),\n",
       " array([0.66777353, 0.        , 0.        ]),\n",
       " array([2011, 1799,  202], dtype=int64))"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y, y_hat_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501246261216351"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_hat_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 150)               1350      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 22,010\n",
      "Trainable params: 22,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_keras, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x3 = train_x\n",
    "train_y3 = train_y2\n",
    "test_x3 = test_x\n",
    "test_y3 = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras2 = keras.Sequential()\n",
    "model_keras2.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras2.add(layers.Dense(100, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras2.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras2.add(layers.Dense(25, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "model_keras2.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model_keras2.compile(keras.optimizers.SGD(learning_rate=0.001), \n",
    "          keras.losses.MeanSquaredError(reduction='sum'),\n",
    "          metrics=['accuracy']\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 2.2230 - accuracy: 0.4545\n",
      "Epoch 2/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9949 - accuracy: 0.4912\n",
      "Epoch 3/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9863 - accuracy: 0.4892\n",
      "Epoch 4/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9822 - accuracy: 0.4923\n",
      "Epoch 5/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9811 - accuracy: 0.4913\n",
      "Epoch 6/25\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9801 - accuracy: 0.4931\n",
      "Epoch 7/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9793 - accuracy: 0.4948\n",
      "Epoch 8/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9778 - accuracy: 0.4944\n",
      "Epoch 9/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9779 - accuracy: 0.4948\n",
      "Epoch 10/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9776 - accuracy: 0.4938\n",
      "Epoch 11/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9768 - accuracy: 0.4928\n",
      "Epoch 12/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9753 - accuracy: 0.4948\n",
      "Epoch 13/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9751 - accuracy: 0.4939\n",
      "Epoch 14/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9748 - accuracy: 0.4951\n",
      "Epoch 15/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9747 - accuracy: 0.4938\n",
      "Epoch 16/25\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9732 - accuracy: 0.4923\n",
      "Epoch 17/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9715 - accuracy: 0.4982\n",
      "Epoch 18/25\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9730 - accuracy: 0.4930: 0s - l\n",
      "Epoch 19/25\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9720 - accuracy: 0.4938\n",
      "Epoch 20/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9717 - accuracy: 0.4943\n",
      "Epoch 21/25\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9717 - accuracy: 0.4949\n",
      "Epoch 22/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9707 - accuracy: 0.4961\n",
      "Epoch 23/25\n",
      "502/502 [==============================] - 1s 2ms/step - loss: 1.9699 - accuracy: 0.4933\n",
      "Epoch 24/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9697 - accuracy: 0.4951\n",
      "Epoch 25/25\n",
      "502/502 [==============================] - 1s 1ms/step - loss: 1.9687 - accuracy: 0.4948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c672dcb610>"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras2.fit(train_x3, train_y3, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_keras2 = model_keras2.predict(test_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5039628 , 0.44859228, 0.00335595, ..., 0.0076759 , 0.00401348,\n",
       "        0.0079568 ],\n",
       "       [0.5039628 , 0.44859228, 0.00335595, ..., 0.0076759 , 0.00401348,\n",
       "        0.0079568 ],\n",
       "       [0.5039628 , 0.44859228, 0.00335595, ..., 0.0076759 , 0.00401348,\n",
       "        0.0079568 ],\n",
       "       ...,\n",
       "       [0.5039628 , 0.44859228, 0.00335595, ..., 0.0076759 , 0.00401348,\n",
       "        0.0079568 ],\n",
       "       [0.5039628 , 0.44859228, 0.00335595, ..., 0.0076759 , 0.00401348,\n",
       "        0.0079568 ],\n",
       "       [0.5039628 , 0.44859228, 0.00335595, ..., 0.0076759 , 0.00401348,\n",
       "        0.0079568 ]], dtype=float32)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_keras2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_keras2 = [np.argmax(y) for y in y_hat_keras2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_keras2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2011,    0,    0],\n",
       "       [1799,    0,    0],\n",
       "       [ 202,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_keras2 = confusion_matrix(test_y3, y_hat_keras2)\n",
    "cm_keras2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50124626, 0.        , 0.        ]),\n",
       " array([1., 0., 0.]),\n",
       " array([0.66777353, 0.        , 0.        ]),\n",
       " array([2011, 1799,  202], dtype=int64))"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(test_y3, y_hat_keras2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501246261216351"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y3, y_hat_keras2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 150)               1350      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 23,035\n",
      "Trainable params: 23,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_keras2, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_conv = keras.Sequential()\n",
    "# model_conv.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "# model_conv.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "# model_conv.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "# model_conv.add(layers.Flatten())\n",
    "# model_conv.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# model_conv.compile(keras.optimizers.Adam(learning_rate=0.001), keras.losses.MeanSquaredError(reduction='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y2 = []\n",
    "# for y in train_y:\n",
    "#     y2 = np.zeros(8)\n",
    "#     y2[y] = 1\n",
    "#     train_y2.append(y2)\n",
    "    \n",
    "# test_y2 = []\n",
    "# for y in test_y:\n",
    "#     y2 = np.zeros(8)\n",
    "#     y2[y] = 1\n",
    "#     test_y2.append(y2)\n",
    "    \n",
    "# train_y2 = np.array(train_y2)\n",
    "# test_y2 = np.array(test_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x3 = train_x\n",
    "# train_y3 = train_y2\n",
    "# test_x3 = test_x\n",
    "# test_y3 = test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x3 = train_x.reshape(16046, 1, -1)\n",
    "# train_y3 = train_y2.reshape(-1, 1, 8)\n",
    "# test_x3 = test_x.reshape(-1, 32096, 1)\n",
    "# test_y3 = test_y2.reshape(-1, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_conv.fit(train_x3, train_y3, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
